{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
    "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in open('corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, TOPN=3):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)\n",
    "    topn = similarities.argsort()[0][:TOPN]\n",
    "    \n",
    "    return [id2word[top] for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 'опофеоз'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['апофеоз', 'апофеозом', 'апофеоза']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_set = get_closest_match_vec(w, X, vec)\n",
    "closest_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "        \n",
    "    return similarities.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.8571428571428572)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_match_with_metric(w, closest_set, textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(word, X, vec):\n",
    "    candidates = get_closest_match_vec(word, X, vec)\n",
    "    #print('candidates: ', candidates)\n",
    "    sims = Counter()\n",
    "    closest = get_closest_match_with_metric(word, candidates)   \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.8571428571428572)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match(w, X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10012"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent = []\n",
    "for i in range(0, len(bad)):\n",
    "    pairs = align_words(true[i],bad[i])\n",
    "    for j in pairs:\n",
    "        all_sent.append(j)\n",
    "len(all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = all_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clos_set = []\n",
    "for i in range(0,len(pairs)):\n",
    "    closest = get_closest_hybrid_match(pairs[i][1], X, vec)\n",
    "    clos_set.append(closest)\n",
    "    #print('closest to \"'+pairs[i][1]+'\" is \"'+closest[0]+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7947463044346784\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "for i in range(0,len(pairs)):\n",
    "    #print('bad: ', pairs[i][1])\n",
    "    #print('true: ', pairs[i][0])\n",
    "    #print('closest: ', clos_set[i], '\\n')\n",
    "    if clos_set[i][0] == pairs[i][0]:\n",
    "        success += 1\n",
    "print(success/len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9153556665771331\n"
     ]
    }
   ],
   "source": [
    "s_all = 0\n",
    "for i in range(0,len(pairs)):\n",
    "    s_all += clos_set[i][1]\n",
    "av_len_all = s_all/len(pairs)\n",
    "print(av_len_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуем улучшить. Сначала я возьму только одно предложение для проверки, и сравню полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продублирую один кусочек кода, и далее добавлю измененный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec_2 = TfidfVectorizer(analyzer='char', ngram_range=(1,4))\n",
    "X_2 = vec_2.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('симпатичнейшее', 'симпатичнейшое'),\n",
       " ('шпионское', 'шпионское'),\n",
       " ('устройство', 'устройство'),\n",
       " ('такой', 'такой'),\n",
       " ('себе', 'себе'),\n",
       " ('гламурный', 'гламурный'),\n",
       " ('фотоаппарат', 'фотоаппарат'),\n",
       " ('девушки', 'девушки'),\n",
       " ('бонда', 'бонда'),\n",
       " ('миниатюрная', 'миниатюрная'),\n",
       " ('модель', 'модель'),\n",
       " ('камеры', 'камеры'),\n",
       " ('superheadz', 'superheadz'),\n",
       " ('clap', 'clap'),\n",
       " ('camera', 'camera')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_small = align_words(true[0],bad[0])\n",
    "pairs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest to \"симпатичнейшое\" is \"пластичнейшими\"\n",
      "closest to \"шпионское\" is \"шпионские\"\n",
      "closest to \"устройство\" is \"устройство\"\n",
      "closest to \"такой\" is \"такой\"\n",
      "closest to \"себе\" is \"себе\"\n",
      "closest to \"гламурный\" is \"гуманный\"\n",
      "closest to \"фотоаппарат\" is \"фотоаппарат\"\n",
      "closest to \"девушки\" is \"девушки\"\n",
      "closest to \"бонда\" is \"банд\"\n",
      "closest to \"миниатюрная\" is \"миниатюрная\"\n",
      "closest to \"модель\" is \"модель\"\n",
      "closest to \"камеры\" is \"камеры\"\n",
      "closest to \"superheadz\" is \"herederas\"\n",
      "closest to \"clap\" is \"place\"\n",
      "closest to \"camera\" is \"america\"\n"
     ]
    }
   ],
   "source": [
    "clos_set_1 = []\n",
    "for i in range(0,len(pairs_small)):\n",
    "    closest_1 = get_closest_hybrid_match(pairs_small[i][1], X, vec)\n",
    "    clos_set_1.append(closest_1)\n",
    "    print('closest to \"'+pairs_small[i][1]+'\" is \"'+closest_1[0]+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "success_1 = 0\n",
    "for i in range(0,len(pairs_small)):\n",
    "    #print('bad: ', pairs_small[i][1])\n",
    "    #print('true: ', pairs_small[i][0])\n",
    "    #print('closest: ', clos_set_1[i], '\\n')\n",
    "    if clos_set_1[i][0] == pairs_small[i][0]:\n",
    "        success_1 += 1\n",
    "print(success_1/len(pairs_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762962962962962\n"
     ]
    }
   ],
   "source": [
    "s_1 = 0\n",
    "for i in range(0,len(pairs_small)):\n",
    "    s_1 += clos_set_1[i][1]\n",
    "av_len_1 = s_1/len(pairs_small)\n",
    "print(av_len_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь второй вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest to \"симпатичнейшое\" is \"симпатичный\"\n",
      "closest to \"шпионское\" is \"шпионской\"\n",
      "closest to \"устройство\" is \"устройство\"\n",
      "closest to \"такой\" is \"такой\"\n",
      "closest to \"себе\" is \"себе\"\n",
      "closest to \"гламурный\" is \"гламур\"\n",
      "closest to \"фотоаппарат\" is \"фотоаппарат\"\n",
      "closest to \"девушки\" is \"девушки\"\n",
      "closest to \"бонда\" is \"бонди\"\n",
      "closest to \"миниатюрная\" is \"миниатюрная\"\n",
      "closest to \"модель\" is \"модель\"\n",
      "closest to \"камеры\" is \"камеры\"\n",
      "closest to \"superheadz\" is \"superjet\"\n",
      "closest to \"clap\" is \"ap\"\n",
      "closest to \"camera\" is \"tamer\"\n"
     ]
    }
   ],
   "source": [
    "clos_set_2 = []\n",
    "for i in range(0,len(pairs_small)):\n",
    "    closest_2 = get_closest_hybrid_match(pairs_small[i][1], X_2, vec_2)\n",
    "    clos_set_2.append(closest_2)\n",
    "    print('closest to \"'+pairs_small[i][1]+'\" is \"'+closest_2[0]+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "success_2 = 0\n",
    "for i in range(0,len(pairs_small)):\n",
    "    #print('bad: ', pairs_small[i][1])\n",
    "    #print('true: ', pairs_small[i][0])\n",
    "    #print('closest: ', clos_set_2[i], '\\n')\n",
    "    if clos_set_2[i][0] == pairs_small[i][0]:\n",
    "        success_2 += 1\n",
    "print(success_2/len(pairs_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557671957671957\n"
     ]
    }
   ],
   "source": [
    "s_2 = 0\n",
    "for i in range(0,len(pairs_small)):\n",
    "    s_2 += clos_set_2[i][1]\n",
    "av_len_2 = s_2/len(pairs_small)\n",
    "print(av_len_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на то, что количество ошибок не изменилось и они допущены в одних и тех же местах, видно, что во втором случае, подбираемые слова, ближе к исходным. Например, для \"симпатичнейшое\" - \"симпатичный\", а не \"пластичнейшими\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я пробовала сделать также для всех предложений, но код долго работал (слишком долго), что никак не удавалось получить результат. Так что, возможно, это не самый лучший спобоб добиться каких-то улучшений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clos_set_3 = []\n",
    "for i in range(0,len(pairs)):\n",
    "    closest_3 = get_closest_hybrid_match(pairs[i][1], X_2, vec_2)\n",
    "    clos_set_3.append(closest_3)\n",
    "    #print('closest to \"'+pairs[i][1]+'\" is \"'+closest_3[0]+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success_3 = 0\n",
    "for i in range(0,len(pairs)):\n",
    "    #print('bad: ', pairs[i][1])\n",
    "    #print('true: ', pairs[i][0])\n",
    "    #print('closest: ', clos_set_3[i], '\\n')\n",
    "    if clos_set_3[i][0] == pairs[i][0]:\n",
    "        success_3 += 1\n",
    "print(success_3/len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_all_2 = 0\n",
    "for i in range(0,len(pairs)):\n",
    "    s_all_2 += clos_set_3[i][1]\n",
    "av_len_all_2 = s_all_2/len(pairs)\n",
    "print(av_len_all_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
